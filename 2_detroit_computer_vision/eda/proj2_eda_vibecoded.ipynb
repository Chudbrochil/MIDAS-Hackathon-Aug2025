{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Detroit Blight Classification - Exploratory Data Analysis\n",
    "\n",
    "This notebook analyzes three Detroit datasets to identify potential blight/inhabitability labels and features:\n",
    "1. **Blight Survey Data** - DLBA property condition assessments\n",
    "2. **COD Layers CSV** - Addresses, Buildings, Parcels with tax/assessment data\n",
    "3. **Geodatabase** - Spatial layers (requires GIS tools)\n",
    "\n",
    "**Primary Goal**: Hunt for blight/inhabitability labels for machine learning classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Detroit Blight Classification EDA - Ready to analyze!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Detroit Blight Classification EDA - Ready to analyze!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Blight Survey Data Analysis - HUNTING FOR LABELS üéØ\n",
    "\n",
    "This is our most promising dataset for blight classification labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üè† BLIGHT SURVEY DATA ANALYSIS - LABEL HUNTING\n",
      "============================================================\n",
      "üìã Dataset Shape: (62824, 30)\n",
      "üìä Number of rows: 62,824\n",
      "üìã Number of columns: 30\n",
      "\n",
      "üéØ POTENTIAL BLIGHT CLASSIFICATION LABELS:\n",
      "==================================================\n",
      "\n",
      "üè∑Ô∏è  FIELD_DETERMINATION:\n",
      "   Unique values: 9\n",
      "   Missing: 14,316 (22.8%)\n",
      "   Values: [' NAP (Salvage)', 'Extreme Evidence of Blight', 'No Action (Salvage)', 'Noticeable Evidence of Blight', 'ODM (Demo)', 'Other Resolution Pathways (Salvage)', 'Property in Pipeline', 'Significant Evidence of Blight', 'Vacant (Not Blighted)']\n",
      "   Value counts:\n",
      "     Noticeable Evidence of Blight: 23,443 (37.3%)\n",
      "     nan: 14,316 (22.8%)\n",
      "     Significant Evidence of Blight: 8,956 (14.3%)\n",
      "     Vacant (Not Blighted): 7,714 (12.3%)\n",
      "     No Action (Salvage): 3,700 (5.9%)\n",
      "      NAP (Salvage): 2,940 (4.7%)\n",
      "     Extreme Evidence of Blight: 1,594 (2.5%)\n",
      "     ODM (Demo): 139 (0.2%)\n",
      "     Property in Pipeline: 20 (0.0%)\n",
      "     Other Resolution Pathways (Salvage): 2 (0.0%)\n",
      "\n",
      "üè∑Ô∏è  FINAL_DETERMINATION:\n",
      "   Unique values: 7\n",
      "   Missing: 22,532 (35.9%)\n",
      "   Values: [' NAP (Salvage)', 'No Action (Salvage)', 'Noticeable Evidence of Blight', 'ODM (Demo)', 'Other Resolution Pathways (Salvage)', 'Property in Pipeline', 'Vacant (Not Blighted)']\n",
      "   Value counts:\n",
      "     nan: 22,532 (35.9%)\n",
      "     Property in Pipeline: 14,547 (23.2%)\n",
      "     Other Resolution Pathways (Salvage): 11,234 (17.9%)\n",
      "     Vacant (Not Blighted): 4,940 (7.9%)\n",
      "     No Action (Salvage): 4,460 (7.1%)\n",
      "      NAP (Salvage): 4,451 (7.1%)\n",
      "     ODM (Demo): 634 (1.0%)\n",
      "     Noticeable Evidence of Blight: 26 (0.0%)\n",
      "\n",
      "üè∑Ô∏è  FINAL_DETERMINATION_2:\n",
      "   Unique values: 7\n",
      "   Missing: 22,532 (35.9%)\n",
      "   Values: ['NAP(Salvage)', 'No Action(Salvage)', 'Noticeable Evidence of Blight', 'ODM(Demo)', 'Other Resolution Pathways(Salvage)', 'Property in Pipeline', 'Vacant (Not Blighted)']\n",
      "   Value counts:\n",
      "     nan: 22,532 (35.9%)\n",
      "     Property in Pipeline: 14,547 (23.2%)\n",
      "     Other Resolution Pathways(Salvage): 11,234 (17.9%)\n",
      "     Vacant (Not Blighted): 4,940 (7.9%)\n",
      "     No Action(Salvage): 4,460 (7.1%)\n",
      "     NAP(Salvage): 4,451 (7.1%)\n",
      "     ODM(Demo): 634 (1.0%)\n",
      "     Noticeable Evidence of Blight: 26 (0.0%)\n",
      "\n",
      "üè∑Ô∏è  OTHER_RESOLUTION_PATHWAYS_DETERMINATION:\n",
      "   Unique values: 49\n",
      "   Missing: 55,432 (88.2%)\n",
      "\n",
      "üè∑Ô∏è  SURVEY_STATUS:\n",
      "   Unique values: 4\n",
      "   Missing: 0 (0.0%)\n",
      "   Values: ['Complete', 'In Progress', 'New', 'QC']\n",
      "   Value counts:\n",
      "     Complete: 56,649 (90.2%)\n",
      "     QC: 3,777 (6.0%)\n",
      "     New: 1,964 (3.1%)\n",
      "     In Progress: 434 (0.7%)\n",
      "\n",
      "üè∑Ô∏è  HAS_STRUCTURE:\n",
      "   Unique values: 2\n",
      "   Missing: 13,160 (20.9%)\n",
      "   Values: [np.float64(0.0), np.float64(1.0)]\n",
      "   Value counts:\n",
      "     1.0: 48,407 (77.1%)\n",
      "     nan: 13,160 (20.9%)\n",
      "     0.0: 1,257 (2.0%)\n",
      "\n",
      "üè∑Ô∏è  IS_OCCUPIED:\n",
      "   Unique values: 2\n",
      "   Missing: 13,865 (22.1%)\n",
      "   Values: [np.float64(0.0), np.float64(1.0)]\n",
      "   Value counts:\n",
      "     0.0: 40,892 (65.1%)\n",
      "     nan: 13,865 (22.1%)\n",
      "     1.0: 8,067 (12.8%)\n",
      "\n",
      "\n",
      "üèöÔ∏è PROPERTY CONDITION FEATURES (for ML features):\n",
      "==================================================\n",
      "\n",
      "üîß FACADE_SIDING_CONDITION:\n",
      "   Unique values: 5\n",
      "   Missing: 21,912 (34.9%)\n",
      "     nan: 21,912 (34.9%)\n",
      "     Peeling Paint Or Small Areas Damaged Siding Or Brick Work: 17,969 (28.6%)\n",
      "     Good Condition: 12,672 (20.2%)\n",
      "     Large Areas Of Facade Damage Or Missing Fa√É¬ßade: 8,961 (14.3%)\n",
      "     Open / Collapsing Areas: 1,196 (1.9%)\n",
      "\n",
      "üîß FIRE_DAMAGE_CONDITION:\n",
      "   Unique values: 6\n",
      "   Missing: 47,522 (75.6%)\n",
      "     nan: 47,522 (75.6%)\n",
      "     No: 7,787 (12.4%)\n",
      "     No Fire Damage: 5,821 (9.3%)\n",
      "     Yes: 1,078 (1.7%)\n",
      "     Superficial √¢¬Ä¬ì Evidence Of Fire, But Damage Is Cosmetic: 296 (0.5%)\n",
      "\n",
      "üîß ROOF_CONDITION:\n",
      "   Unique values: 5\n",
      "   Missing: 21,609 (34.4%)\n",
      "     nan: 21,609 (34.4%)\n",
      "     Good Condition: 20,391 (32.5%)\n",
      "     Small Areas Of Damaged Shingles: 11,235 (17.9%)\n",
      "     Missing Shingles Or Large Areas Of Damaged Shingles (Tarp): 6,517 (10.4%)\n",
      "     Open / Sagging/ Collapsing: 2,954 (4.7%)\n",
      "\n",
      "üîß OPENINGS_CONDITION:\n",
      "   Unique values: 5\n",
      "   Missing: 21,874 (34.8%)\n",
      "     nan: 21,874 (34.8%)\n",
      "     More Than 50% Missing Windows Or Majority Openings Boarded: 14,098 (22.4%)\n",
      "     Some Missing Windows Or Boarded Openings: 12,621 (20.1%)\n",
      "     Windows And Doors In Good Condition: 11,536 (18.4%)\n",
      "     Majority Of Openings Uncovered: 2,610 (4.2%)\n",
      "\n",
      "üîß IS_OPEN_TO_TRESPASS:\n",
      "   Unique values: 1\n",
      "   Missing: 0 (0.0%)\n",
      "     False: 62,824 (100.0%)\n",
      "\n",
      "üîß PORCH_STEPS_CONDITION:\n",
      "   Unique values: 5\n",
      "   Missing: 23,609 (37.6%)\n",
      "     nan: 23,609 (37.6%)\n",
      "     Good Condition: 20,268 (32.3%)\n",
      "     Damaged steps or missing brickwork/ siding: 13,439 (21.4%)\n",
      "     Sagging Porches: 2,894 (4.6%)\n",
      "     Collapsing: 2,518 (4.0%)\n",
      "\n",
      "üìù Column Information (All columns):\n",
      "----------------------------------------\n",
      " 1. ACCOUNT_ID                          | object          |     0 nulls (  0.0%)\n",
      " 2. PARCEL_ID                           | object          |     0 nulls (  0.0%)\n",
      " 3. NAME                                | object          |     0 nulls (  0.0%)\n",
      " 4. FIELD_SURVEY_ID                     | object          |     0 nulls (  0.0%)\n",
      " 5. FIELD_SURVEY_NAME                   | object          |     0 nulls (  0.0%)\n",
      " 6. RECORD_TYPE_ID                      | object          |     0 nulls (  0.0%)\n",
      " 7. PROPERTY_ACCOUNT_ID                 | object          |     0 nulls (  0.0%)\n",
      " 8. CASE_ID                             | object          | 29619 nulls ( 47.1%)\n",
      " 9. SURVEY_ITERATION                    | object          |     0 nulls (  0.0%)\n",
      "10. SURVEY_BATCH                        | object          | 18096 nulls ( 28.8%)\n",
      "11. SURVEY_STATUS                       | object          |     0 nulls (  0.0%)\n",
      "12. DATE_SURVEYED                       | object          |   309 nulls (  0.5%)\n",
      "13. DATE_REVIEWED                       | datetime64[ns]  | 22553 nulls ( 35.9%)\n",
      "14. FIELD_DETERMINATION                 | object          | 14316 nulls ( 22.8%)\n",
      "15. FINAL_DETERMINATION                 | object          | 22532 nulls ( 35.9%)\n",
      "16. FINAL_DETERMINATION_2               | object          | 22532 nulls ( 35.9%)\n",
      "17. OTHER_RESOLUTION_PATHWAYS_DETERMINATION | object          | 55432 nulls ( 88.2%)\n",
      "18. SURVEYOR_NOTES                      | object          |  2593 nulls (  4.1%)\n",
      "19. REVIEWER_NOTES                      | object          | 29619 nulls ( 47.1%)\n",
      "20. SURVEY_PHOTO_URL                    | object          |   129 nulls (  0.2%)\n",
      "21. HAS_STRUCTURE                       | float64         | 13160 nulls ( 20.9%)\n",
      "22. IS_OCCUPIED                         | float64         | 13865 nulls ( 22.1%)\n",
      "23. FACADE_SIDING_CONDITION             | object          | 21912 nulls ( 34.9%)\n",
      "24. FIRE_DAMAGE_CONDITION               | object          | 47522 nulls ( 75.6%)\n",
      "25. ROOF_CONDITION                      | object          | 21609 nulls ( 34.4%)\n",
      "26. OPENINGS_CONDITION                  | object          | 21874 nulls ( 34.8%)\n",
      "27. IS_OPEN_TO_TRESPASS                 | bool            |     0 nulls (  0.0%)\n",
      "28. PORCH_STEPS_CONDITION               | object          | 23609 nulls ( 37.6%)\n",
      "29. CREATED_AT                          | datetime64[ns]  |     0 nulls (  0.0%)\n",
      "30. LAST_MODIFIED_AT                    | datetime64[ns]  |     0 nulls (  0.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_blight_survey_data():\n",
    "    \"\"\"\n",
    "    Analyze the Detroit Land Bank Authority blight survey data\n",
    "    Focus on finding classification labels for blight/inhabitability\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üè† BLIGHT SURVEY DATA ANALYSIS - LABEL HUNTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load the Excel file - Updated path for new location\n",
    "    file_path = \"../../data/blight_survey_data/20250527_DLBA_survey_data_UM_Detroit.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        print(f\"üìã Dataset Shape: {df.shape}\")\n",
    "        print(f\"üìä Number of rows: {df.shape[0]:,}\")\n",
    "        print(f\"üìã Number of columns: {df.shape[1]}\")\n",
    "        print()\n",
    "        \n",
    "        # Focus on potential LABEL columns\n",
    "        label_candidates = [\n",
    "            'FIELD_DETERMINATION', 'FINAL_DETERMINATION', 'FINAL_DETERMINATION_2',\n",
    "            'OTHER_RESOLUTION_PATHWAYS_DETERMINATION', 'SURVEY_STATUS',\n",
    "            'HAS_STRUCTURE', 'IS_OCCUPIED'\n",
    "        ]\n",
    "        \n",
    "        print(\"üéØ POTENTIAL BLIGHT CLASSIFICATION LABELS:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for col in label_candidates:\n",
    "            if col in df.columns:\n",
    "                null_count = df[col].isnull().sum()\n",
    "                null_pct = (null_count / len(df)) * 100\n",
    "                unique_vals = df[col].nunique()\n",
    "                \n",
    "                print(f\"\\nüè∑Ô∏è  {col}:\")\n",
    "                print(f\"   Unique values: {unique_vals}\")\n",
    "                print(f\"   Missing: {null_count:,} ({null_pct:.1f}%)\")\n",
    "                \n",
    "                if unique_vals <= 20 and unique_vals > 0:\n",
    "                    print(f\"   Values: {sorted(df[col].dropna().unique())}\")\n",
    "                    print(f\"   Value counts:\")\n",
    "                    value_counts = df[col].value_counts(dropna=False)\n",
    "                    for val, count in value_counts.head(10).items():\n",
    "                        pct = (count / len(df)) * 100\n",
    "                        print(f\"     {val}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Look at condition assessment columns\n",
    "        condition_cols = [\n",
    "            'FACADE_SIDING_CONDITION', 'FIRE_DAMAGE_CONDITION', 'ROOF_CONDITION',\n",
    "            'OPENINGS_CONDITION', 'IS_OPEN_TO_TRESPASS', 'PORCH_STEPS_CONDITION'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n\\nüèöÔ∏è PROPERTY CONDITION FEATURES (for ML features):\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for col in condition_cols:\n",
    "            if col in df.columns:\n",
    "                null_count = df[col].isnull().sum()\n",
    "                null_pct = (null_count / len(df)) * 100\n",
    "                unique_vals = df[col].nunique()\n",
    "                \n",
    "                print(f\"\\nüîß {col}:\")\n",
    "                print(f\"   Unique values: {unique_vals}\")\n",
    "                print(f\"   Missing: {null_count:,} ({null_pct:.1f}%)\")\n",
    "                \n",
    "                if unique_vals <= 15 and unique_vals > 0:\n",
    "                    value_counts = df[col].value_counts(dropna=False)\n",
    "                    for val, count in value_counts.head(5).items():\n",
    "                        pct = (count / len(df)) * 100\n",
    "                        print(f\"     {val}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nüìù Column Information (All columns):\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            dtype = str(df[col].dtype)\n",
    "            null_count = df[col].isnull().sum()\n",
    "            null_pct = (null_count / len(df)) * 100\n",
    "            print(f\"{i:2d}. {col:<35} | {dtype:<15} | {null_count:>5} nulls ({null_pct:5.1f}%)\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading blight survey data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the analysis\n",
    "blight_df = analyze_blight_survey_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. COD Layers Analysis - More Label Hunting üîç\n",
    "\n",
    "Looking for blight indicators in the City of Detroit address, building, and parcel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèôÔ∏è COD LAYERS CSV DATA ANALYSIS - BLIGHT HUNTING\n",
      "============================================================\n",
      "\n",
      "üè¢ ADDRESSES Dataset:\n",
      "--------------------------------------------------\n",
      "üìä Dataset Shape: (490561, 12)\n",
      "üìã Rows: 490,561, Columns: 12\n",
      "\n",
      "üìù All Columns (12):\n",
      "   1. OBJECTID                       | int64           |      0 nulls (  0.0%)\n",
      "   2. addr_id                        | int64           |      0 nulls (  0.0%)\n",
      "   3. unit_id                        | float64         | 366083 nulls ( 74.6%)\n",
      "   4. bldg_id                        | float64         | 128409 nulls ( 26.2%)\n",
      "   5. parcel_id                      | object          |    913 nulls (  0.2%)\n",
      "   6. street_id                      | float64         |   1278 nulls (  0.3%)\n",
      "   7. street_number                  | int64           |      0 nulls (  0.0%)\n",
      "   8. unit_type                      | object          | 428115 nulls ( 87.3%)\n",
      "   9. unit_number                    | object          | 412708 nulls ( 84.1%)\n",
      "  10. streetname_id                  | float64         | 376732 nulls ( 76.8%)\n",
      "  11. zip_code                       | float64         |   1878 nulls (  0.4%)\n",
      "  12. zip_four                       | float64         | 214395 nulls ( 43.7%)\n",
      "\n",
      "üè¢ BUILDINGS Dataset:\n",
      "--------------------------------------------------\n",
      "üìä Dataset Shape: (409301, 8)\n",
      "üìã Rows: 409,301, Columns: 8\n",
      "\n",
      "üéØ POTENTIAL BLIGHT INDICATORS (1 found):\n",
      "\n",
      "   üè∑Ô∏è bldg_status:\n",
      "      Unique values: 3, Missing: 0.0%\n",
      "        Current: 365,940 (89.4%)\n",
      "        Retired: 43,131 (10.5%)\n",
      "        Pending: 230 (0.1%)\n",
      "\n",
      "üìù All Columns (8):\n",
      "   1. OBJECTID_1                     | int64           |      0 nulls (  0.0%)\n",
      "   2. objectid                       | float64         | 409301 nulls (100.0%)\n",
      "   3. bldg_id                        | int64           |      0 nulls (  0.0%)\n",
      "   4. parcel_id                      | object          |     50 nulls (  0.0%)\n",
      "   5. addr_id                        | float64         | 409301 nulls (100.0%)\n",
      "üéØ 6. bldg_status                    | object          |      0 nulls (  0.0%)\n",
      "   7. Shape__Area                    | float64         |      0 nulls (  0.0%)\n",
      "   8. Shape__Length                  | float64         |      0 nulls (  0.0%)\n",
      "\n",
      "üè¢ PARCELS2025 Dataset:\n",
      "--------------------------------------------------\n",
      "üìä Dataset Shape: (378366, 52)\n",
      "üìã Rows: 378,366, Columns: 52\n",
      "\n",
      "üéØ POTENTIAL BLIGHT INDICATORS (16 found):\n",
      "\n",
      "   üè∑Ô∏è Taxpayer 1:\n",
      "      Unique values: 211688, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Taxpayer 2:\n",
      "      Unique values: 7166, Missing: 96.7%\n",
      "\n",
      "   üè∑Ô∏è Taxpayer Address:\n",
      "      Unique values: 223970, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Taxpayer City:\n",
      "      Unique values: 3101, Missing: 0.3%\n",
      "\n",
      "   üè∑Ô∏è Taxpayer State:\n",
      "      Unique values: 75, Missing: 0.3%\n",
      "\n",
      "   üè∑Ô∏è Taxpayer ZIP Code:\n",
      "      Unique values: 34058, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Property Class:\n",
      "      Unique values: 10, Missing: 0.0%\n",
      "        401.0: 217,612 (57.5%)\n",
      "        402.0: 116,720 (30.8%)\n",
      "        202.0: 16,430 (4.3%)\n",
      "        201.0: 15,218 (4.0%)\n",
      "        407.0: 6,197 (1.6%)\n",
      "\n",
      "   üè∑Ô∏è Property Class Description:\n",
      "      Unique values: 10, Missing: 0.0%\n",
      "        RESIDENTIAL-IMPROVED: 217,612 (57.5%)\n",
      "        RESIDENTIAL-VACANT: 116,720 (30.8%)\n",
      "        COMMERCIAL-VACANT: 16,430 (4.3%)\n",
      "        COMMERCIAL-IMPROVED: 15,218 (4.0%)\n",
      "        RESIDENTIAL CONDOMINIUMS: 6,197 (1.6%)\n",
      "\n",
      "   üè∑Ô∏è Previous Property Class:\n",
      "      Unique values: 10, Missing: 0.0%\n",
      "        401.0: 217,816 (57.6%)\n",
      "        402.0: 116,522 (30.8%)\n",
      "        202.0: 16,434 (4.3%)\n",
      "        201.0: 15,223 (4.0%)\n",
      "        407.0: 6,196 (1.6%)\n",
      "\n",
      "   üè∑Ô∏è Tax Status:\n",
      "      Unique values: 24, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Tax Status Description:\n",
      "      Unique values: 24, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Previous Tax Status:\n",
      "      Unique values: 24, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Assessed Value:\n",
      "      Unique values: 5836, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Previous Assessed Value:\n",
      "      Unique values: 5655, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Taxable Value:\n",
      "      Unique values: 20825, Missing: 0.0%\n",
      "\n",
      "   üè∑Ô∏è Previous Taxable Value:\n",
      "      Unique values: 19583, Missing: 0.0%\n",
      "\n",
      "üìù All Columns (52):\n",
      "   1. object_id                      | int64           |      0 nulls (  0.0%)\n",
      "   2. Parcel ID                      | object          |      0 nulls (  0.0%)\n",
      "   3. Address                        | object          |     33 nulls (  0.0%)\n",
      "   4. ZIP Code                       | object          |   1753 nulls (  0.5%)\n",
      "üéØ 5. Taxpayer 1                     | object          |     38 nulls (  0.0%)\n",
      "üéØ 6. Taxpayer 2                     | object          | 366008 nulls ( 96.7%)\n",
      "üéØ 7. Taxpayer Address               | object          |     55 nulls (  0.0%)\n",
      "üéØ 8. Taxpayer City                  | object          |   1014 nulls (  0.3%)\n",
      "üéØ 9. Taxpayer State                 | object          |   1021 nulls (  0.3%)\n",
      "üéØ10. Taxpayer ZIP Code              | object          |     90 nulls (  0.0%)\n",
      "üéØ11. Property Class                 | float64         |     32 nulls (  0.0%)\n",
      "üéØ12. Property Class Description     | object          |     32 nulls (  0.0%)\n",
      "üéØ13. Previous Property Class        | float64         |     32 nulls (  0.0%)\n",
      "  14. Use Code                       | object          |   5207 nulls (  1.4%)\n",
      "  15. Use Code Description           | object          |  28971 nulls (  7.7%)\n",
      "  16. Zoning District                | object          |   2481 nulls (  0.7%)\n",
      "  17. Year Built                     | float64         | 146902 nulls ( 38.8%)\n",
      "  18. Building Style                 | object          | 147155 nulls ( 38.9%)\n",
      "  19. Building Count                 | float64         |     32 nulls (  0.0%)\n",
      "  20. Total Floor Area               | float64         | 146283 nulls ( 38.7%)\n",
      "üéØ21. Tax Status                     | object          |     32 nulls (  0.0%)\n",
      "üéØ22. Tax Status Description         | object          |     32 nulls (  0.0%)\n",
      "üéØ23. Previous Tax Status            | object          |     32 nulls (  0.0%)\n",
      "üéØ24. Assessed Value                 | float64         |     32 nulls (  0.0%)\n",
      "üéØ25. Previous Assessed Value        | float64         |     32 nulls (  0.0%)\n",
      "üéØ26. Taxable Value                  | float64         |     32 nulls (  0.0%)\n",
      "üéØ27. Previous Taxable Value         | float64         |     32 nulls (  0.0%)\n",
      "  28. Principal Residence Exemption % Claimed | float64         |     32 nulls (  0.0%)\n",
      "  29. NEZ District                   | object          | 302265 nulls ( 79.9%)\n",
      "  30. ECF Neighborhood               | object          |     34 nulls (  0.0%)\n",
      "  31. Is Improved                    | float64         |     32 nulls (  0.0%)\n",
      "  32. Related Parcel ID              | object          | 362389 nulls ( 95.8%)\n",
      "  33. Sale Date                      | object          |  94808 nulls ( 25.1%)\n",
      "  34. Sale Price                     | float64         |     32 nulls (  0.0%)\n",
      "  35. Total Square Footage           | float64         |     32 nulls (  0.0%)\n",
      "  36. Total Acreage                  | float64         |     32 nulls (  0.0%)\n",
      "  37. Frontage                       | float64         |     32 nulls (  0.0%)\n",
      "  38. Depth                          | float64         |     32 nulls (  0.0%)\n",
      "  39. Parcel Modified Date           | object          | 254047 nulls ( 67.1%)\n",
      "  40. Legal Description              | object          |     88 nulls (  0.0%)\n",
      "  41. Ward                           | float64         |     32 nulls (  0.0%)\n",
      "  42. Landmap                        | object          |    179 nulls (  0.0%)\n",
      "  43. Subdivision                    | object          | 360974 nulls ( 95.4%)\n",
      "  44. Local Historic District        | object          | 368146 nulls ( 97.3%)\n",
      "  45. Neighborhood                   | object          |    871 nulls (  0.2%)\n",
      "  46. Council District               | float64         |     32 nulls (  0.0%)\n",
      "  47. Street Number                  | float64         |     32 nulls (  0.0%)\n",
      "  48. Street Prefix                  | object          | 351540 nulls ( 92.9%)\n",
      "  49. Street Name                    | object          |     33 nulls (  0.0%)\n",
      "  50. ObjectId                       | int64           |      0 nulls (  0.0%)\n",
      "  51. Shape__Area                    | float64         |      0 nulls (  0.0%)\n",
      "  52. Shape__Length                  | float64         |      0 nulls (  0.0%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_cod_layers_csv():\n",
    "    \"\"\"\n",
    "    Analyze the City of Detroit (COD) layers CSV data\n",
    "    Hunt for blight/inhabitability indicators\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üèôÔ∏è COD LAYERS CSV DATA ANALYSIS - BLIGHT HUNTING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Updated path for new location\n",
    "    data_dir = \"../../data/cod_layers_csv/20250728_CODLayers.csv\"\n",
    "    csv_files = [\"Addresses.csv\", \"Buildings.csv\", \"Parcels2025.csv\"]\n",
    "    \n",
    "    datasets = {}\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(data_dir, csv_file)\n",
    "        dataset_name = csv_file.replace('.csv', '')\n",
    "        \n",
    "        print(f\"\\nüè¢ {dataset_name.upper()} Dataset:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "            datasets[dataset_name] = df\n",
    "            \n",
    "            print(f\"üìä Dataset Shape: {df.shape}\")\n",
    "            print(f\"üìã Rows: {df.shape[0]:,}, Columns: {df.shape[1]}\")\n",
    "            \n",
    "            # Hunt for blight-related columns\n",
    "            blight_keywords = ['status', 'condition', 'class', 'vacant', 'occupied', 'tax', 'value', 'assessment']\n",
    "            \n",
    "            potential_blight_cols = []\n",
    "            for col in df.columns:\n",
    "                for keyword in blight_keywords:\n",
    "                    if keyword.lower() in col.lower():\n",
    "                        potential_blight_cols.append(col)\n",
    "                        break\n",
    "            \n",
    "            if potential_blight_cols:\n",
    "                print(f\"\\nüéØ POTENTIAL BLIGHT INDICATORS ({len(potential_blight_cols)} found):\")\n",
    "                for col in potential_blight_cols:\n",
    "                    unique_vals = df[col].nunique()\n",
    "                    null_count = df[col].isnull().sum()\n",
    "                    null_pct = (null_count / len(df)) * 100\n",
    "                    \n",
    "                    print(f\"\\n   üè∑Ô∏è {col}:\")\n",
    "                    print(f\"      Unique values: {unique_vals}, Missing: {null_pct:.1f}%\")\n",
    "                    \n",
    "                    if unique_vals <= 20 and unique_vals > 0:\n",
    "                        value_counts = df[col].value_counts(dropna=False)\n",
    "                        for val, count in value_counts.head(5).items():\n",
    "                            pct = (count / len(df)) * 100\n",
    "                            print(f\"        {val}: {count:,} ({pct:.1f}%)\")\n",
    "            \n",
    "            # Show all columns for reference\n",
    "            print(f\"\\nüìù All Columns ({df.shape[1]}):\")    \n",
    "            for i, col in enumerate(df.columns, 1):\n",
    "                dtype = str(df[col].dtype)\n",
    "                null_count = df[col].isnull().sum()\n",
    "                null_pct = (null_count / len(df)) * 100\n",
    "                blight_flag = \"üéØ\" if col in potential_blight_cols else \"  \"\n",
    "                print(f\"{blight_flag}{i:2d}. {col:<30} | {dtype:<15} | {null_count:>6} nulls ({null_pct:5.1f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {csv_file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Run the analysis\n",
    "cod_datasets = analyze_cod_layers_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Dive into Parcels Data - Tax and Assessment Indicators üí∞\n",
    "\n",
    "The Parcels2025 dataset likely has the richest blight indicators through tax status, property values, and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè° PARCELS 2025 - DEEP DIVE FOR BLIGHT LABELS\n",
      "============================================================\n",
      "\n",
      "üîç Tax Status:\n",
      "   Unique: 24, Missing: 0.0%\n",
      "   Top values:\n",
      "     TAXABLE: 298,133 (78.8%)\n",
      "     EXEMPT (211.7GG): 61,925 (16.4%)\n",
      "     EXEMPT (211.7M): 8,977 (2.4%)\n",
      "     EXEMPT (211.7S): 3,468 (0.9%)\n",
      "     EXEMPT (125.1415A): 1,595 (0.4%)\n",
      "     EXEMPT (211.7L): 1,098 (0.3%)\n",
      "     EXEMPT (211.7O): 931 (0.2%)\n",
      "     EXEMPT (211.7N): 483 (0.1%)\n",
      "     EXEMPT (211.7Z): 404 (0.1%)\n",
      "     EXEMPT (OTHER): 385 (0.1%)\n",
      "\n",
      "üîç Tax Status Description:\n",
      "   Unique: 24, Missing: 0.0%\n",
      "   Top values:\n",
      "     TAXABLE: 298,133 (78.8%)\n",
      "     PROPERTY HELD BY LAND BANK FAST TRACK AUTHORITY: 61,925 (16.4%)\n",
      "     COUNTY, TOWNSHIP, CITY, VILLAGE, SCHOOL DISTRICT, PARKS: 8,977 (2.4%)\n",
      "     HOUSES OF PUBLIC WORSHIP; PARSONAGE: 3,468 (0.9%)\n",
      "     EXEMPTION FROM HOUSING PROJECTS: 1,595 (0.4%)\n",
      "     STATE PROPERTY: 1,098 (0.3%)\n",
      "     NON-PROFIT CHARITABLE INSTITUTION: 931 (0.2%)\n",
      "     NON-PROFIT THEATER, LIBRARY, EDUCATIONAL, SCIENTIFIC INSTITUTION: 483 (0.1%)\n",
      "     SCHOOL: 404 (0.1%)\n",
      "      : 385 (0.1%)\n",
      "\n",
      "üîç Property Class:\n",
      "   Unique: 10, Missing: 0.0%\n",
      "   Top values:\n",
      "     401.0: 217,612 (57.5%)\n",
      "     402.0: 116,720 (30.8%)\n",
      "     202.0: 16,430 (4.3%)\n",
      "     201.0: 15,218 (4.0%)\n",
      "     407.0: 6,197 (1.6%)\n",
      "     302.0: 3,316 (0.9%)\n",
      "     301.0: 2,558 (0.7%)\n",
      "     207.0: 262 (0.1%)\n",
      "     nan: 32 (0.0%)\n",
      "     307.0: 15 (0.0%)\n",
      "\n",
      "üîç Property Class Description:\n",
      "   Unique: 10, Missing: 0.0%\n",
      "   Top values:\n",
      "     RESIDENTIAL-IMPROVED: 217,612 (57.5%)\n",
      "     RESIDENTIAL-VACANT: 116,720 (30.8%)\n",
      "     COMMERCIAL-VACANT: 16,430 (4.3%)\n",
      "     COMMERCIAL-IMPROVED: 15,218 (4.0%)\n",
      "     RESIDENTIAL CONDOMINIUMS: 6,197 (1.6%)\n",
      "     INDUSTRIAL-VACANT: 3,316 (0.9%)\n",
      "     INDUSTRIAL-IMPROVED: 2,558 (0.7%)\n",
      "     COMMERCIAL CONDOMINIUMS: 262 (0.1%)\n",
      "     nan: 32 (0.0%)\n",
      "     INDUSTRIAL CONDOMINIUMS: 15 (0.0%)\n",
      "\n",
      "üîç Use Code:\n",
      "   Unique: 182, Missing: 1.4%\n",
      "\n",
      "üîç Use Code Description:\n",
      "   Unique: 113, Missing: 7.7%\n",
      "\n",
      "üîç Assessed Value:\n",
      "   Unique: 5836, Missing: 0.0%\n",
      "   Stats: Mean=42934.89, Median=17700.00\n",
      "   Range: 0.00 to 495851400.00\n",
      "\n",
      "üîç Taxable Value:\n",
      "   Unique: 20825, Missing: 0.0%\n",
      "   Stats: Mean=19814.48, Median=6820.00\n",
      "   Range: 0.00 to 232659200.00\n",
      "\n",
      "üîç Sale Price:\n",
      "   Unique: 22980, Missing: 0.0%\n",
      "   Stats: Mean=48569.30, Median=12000.00\n",
      "   Range: 0.00 to 110000000.00\n",
      "\n",
      "üîç Is Improved:\n",
      "   Unique: 2, Missing: 0.0%\n",
      "   Top values:\n",
      "     1.0: 231,704 (61.2%)\n",
      "     0.0: 146,630 (38.8%)\n",
      "     nan: 32 (0.0%)\n",
      "\n",
      "üîç Year Built:\n",
      "   Unique: 173, Missing: 38.8%\n",
      "   Stats: Mean=1937.79, Median=1940.00\n",
      "   Range: 1684.00 to 2107.00\n",
      "\n",
      "üîç Building Style:\n",
      "   Unique: 168, Missing: 38.9%\n",
      "\n",
      "üîç Building Count:\n",
      "   Unique: 41, Missing: 0.0%\n",
      "   Top values:\n",
      "     1.0: 225,107 (59.5%)\n",
      "     0.0: 146,632 (38.8%)\n",
      "     2.0: 3,715 (1.0%)\n",
      "     3.0: 1,375 (0.4%)\n",
      "     4.0: 587 (0.2%)\n",
      "     5.0: 301 (0.1%)\n",
      "     6.0: 178 (0.0%)\n",
      "     8.0: 89 (0.0%)\n",
      "     7.0: 88 (0.0%)\n",
      "     9.0: 58 (0.0%)\n",
      "\n",
      "üí∞ LOW VALUE PROPERTIES (Potential Blight Indicators):\n",
      "--------------------------------------------------\n",
      "Properties with $0 Assessed Value: 88,434 (23.4%)\n",
      "Properties with <$1,000 Assessed Value: 118,084 (31.2%)\n",
      "Properties with $0 Sale Price: 95,675 (25.3%)\n"
     ]
    }
   ],
   "source": [
    "# Deep dive into Parcels data for blight indicators\n",
    "if 'Parcels2025' in cod_datasets:\n",
    "    parcels_df = cod_datasets['Parcels2025']\n",
    "    \n",
    "    print(\"üè° PARCELS 2025 - DEEP DIVE FOR BLIGHT LABELS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Key columns that might indicate blight\n",
    "    key_blight_cols = [\n",
    "        'Tax Status', 'Tax Status Description', 'Property Class', 'Property Class Description',\n",
    "        'Use Code', 'Use Code Description', 'Assessed Value', 'Taxable Value', \n",
    "        'Sale Price', 'Is Improved', 'Year Built', 'Building Style', 'Building Count'\n",
    "    ]\n",
    "    \n",
    "    for col in key_blight_cols:\n",
    "        if col in parcels_df.columns:\n",
    "            print(f\"\\nüîç {col}:\")\n",
    "            \n",
    "            unique_vals = parcels_df[col].nunique()\n",
    "            null_count = parcels_df[col].isnull().sum()\n",
    "            null_pct = (null_count / len(parcels_df)) * 100\n",
    "            \n",
    "            print(f\"   Unique: {unique_vals}, Missing: {null_pct:.1f}%\")\n",
    "            \n",
    "            if unique_vals <= 50 and unique_vals > 0:\n",
    "                print(\"   Top values:\")\n",
    "                value_counts = parcels_df[col].value_counts(dropna=False)\n",
    "                for val, count in value_counts.head(10).items():\n",
    "                    pct = (count / len(parcels_df)) * 100\n",
    "                    print(f\"     {val}: {count:,} ({pct:.1f}%)\")\n",
    "            elif parcels_df[col].dtype in ['int64', 'float64']:\n",
    "                print(f\"   Stats: Mean={parcels_df[col].mean():.2f}, Median={parcels_df[col].median():.2f}\")\n",
    "                print(f\"   Range: {parcels_df[col].min():.2f} to {parcels_df[col].max():.2f}\")\n",
    "    \n",
    "    # Look for zero/low value properties (potential blight indicator)\n",
    "    print(\"\\nüí∞ LOW VALUE PROPERTIES (Potential Blight Indicators):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Zero assessed value\n",
    "    zero_assessed = (parcels_df['Assessed Value'] == 0).sum()\n",
    "    zero_assessed_pct = (zero_assessed / len(parcels_df)) * 100\n",
    "    print(f\"Properties with $0 Assessed Value: {zero_assessed:,} ({zero_assessed_pct:.1f}%)\")\n",
    "    \n",
    "    # Very low assessed value (under $1000)\n",
    "    low_assessed = (parcels_df['Assessed Value'] < 1000).sum()\n",
    "    low_assessed_pct = (low_assessed / len(parcels_df)) * 100\n",
    "    print(f\"Properties with <$1,000 Assessed Value: {low_assessed:,} ({low_assessed_pct:.1f}%)\")\n",
    "    \n",
    "    # Zero sale price\n",
    "    zero_sale = (parcels_df['Sale Price'] == 0).sum()\n",
    "    zero_sale_pct = (zero_sale / len(parcels_df)) * 100\n",
    "    print(f\"Properties with $0 Sale Price: {zero_sale:,} ({zero_sale_pct:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Parcels2025 data not available for deep dive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Label Creation Strategy üéØ\n",
    "\n",
    "Based on our analysis, let's create potential blight classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ CREATING BLIGHT CLASSIFICATION LABELS\n",
      "==================================================\n",
      "\n",
      "üè† BLIGHT SURVEY LABELS:\n",
      "------------------------------\n",
      "‚úÖ FINAL_DETERMINATION: 40,292 valid labels\n",
      "   Categories: 7\n",
      "‚úÖ FIELD_DETERMINATION: 48,508 valid labels\n",
      "   Categories: 9\n",
      "\n",
      "üè° PARCELS-BASED LABELS:\n",
      "------------------------------\n",
      "‚úÖ LOW VALUE BLIGHT (< $1000): 29,650 properties (7.8%)\n",
      "‚úÖ TAX STATUS LABELS: 24 categories\n",
      "   TAXABLE: 298,133 (78.8%)\n",
      "   PROPERTY HELD BY LAND BANK FAST TRACK AUTHORITY: 61,925 (16.4%)\n",
      "   COUNTY, TOWNSHIP, CITY, VILLAGE, SCHOOL DISTRICT, PARKS: 8,977 (2.4%)\n",
      "   HOUSES OF PUBLIC WORSHIP; PARSONAGE: 3,468 (0.9%)\n",
      "   EXEMPTION FROM HOUSING PROJECTS: 1,595 (0.4%)\n",
      "\n",
      "üéØ RECOMMENDED LABELING STRATEGY:\n",
      "========================================\n",
      "1. PRIMARY: Use FINAL_DETERMINATION from blight survey (highest quality)\n",
      "2. SECONDARY: Use FIELD_DETERMINATION as backup/additional data\n",
      "3. FEATURES: Combine with property conditions, tax status, assessed values\n",
      "4. AUGMENT: Create synthetic labels using low assessed values\n"
     ]
    }
   ],
   "source": [
    "def create_blight_labels(blight_df, parcels_df):\n",
    "    \"\"\"\n",
    "    Create potential blight classification labels from the datasets\n",
    "    \"\"\"\n",
    "    print(\"üéØ CREATING BLIGHT CLASSIFICATION LABELS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    labels_summary = {}\n",
    "    \n",
    "    if blight_df is not None:\n",
    "        print(\"\\nüè† BLIGHT SURVEY LABELS:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Option 1: Final Determination as primary label\n",
    "        if 'FINAL_DETERMINATION' in blight_df.columns:\n",
    "            valid_determinations = blight_df['FINAL_DETERMINATION'].dropna()\n",
    "            labels_summary['final_determination'] = {\n",
    "                'count': len(valid_determinations),\n",
    "                'unique_values': valid_determinations.nunique(),\n",
    "                'distribution': valid_determinations.value_counts().to_dict()\n",
    "            }\n",
    "            print(f\"‚úÖ FINAL_DETERMINATION: {len(valid_determinations):,} valid labels\")\n",
    "            print(f\"   Categories: {valid_determinations.nunique()}\")\n",
    "            \n",
    "        # Option 2: Field Determination as backup\n",
    "        if 'FIELD_DETERMINATION' in blight_df.columns:\n",
    "            valid_field = blight_df['FIELD_DETERMINATION'].dropna()\n",
    "            labels_summary['field_determination'] = {\n",
    "                'count': len(valid_field),\n",
    "                'unique_values': valid_field.nunique(),\n",
    "                'distribution': valid_field.value_counts().to_dict()\n",
    "            }\n",
    "            print(f\"‚úÖ FIELD_DETERMINATION: {len(valid_field):,} valid labels\")\n",
    "            print(f\"   Categories: {valid_field.nunique()}\")\n",
    "    \n",
    "    if 'Parcels2025' in cod_datasets:\n",
    "        print(\"\\nüè° PARCELS-BASED LABELS:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Create binary blight indicator based on low property values\n",
    "        low_value_threshold = 1000\n",
    "        blight_indicator = (parcels_df['Assessed Value'] < low_value_threshold) & (parcels_df['Assessed Value'] > 0)\n",
    "        \n",
    "        blight_count = blight_indicator.sum()\n",
    "        blight_pct = (blight_count / len(parcels_df)) * 100\n",
    "        \n",
    "        labels_summary['low_value_blight'] = {\n",
    "            'count': len(parcels_df),\n",
    "            'blight_properties': blight_count,\n",
    "            'blight_percentage': blight_pct\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ LOW VALUE BLIGHT (< ${low_value_threshold}): {blight_count:,} properties ({blight_pct:.1f}%)\")\n",
    "        \n",
    "        # Tax status based labels\n",
    "        if 'Tax Status Description' in parcels_df.columns:\n",
    "            tax_status_counts = parcels_df['Tax Status Description'].value_counts()\n",
    "            labels_summary['tax_status'] = tax_status_counts.to_dict()\n",
    "            print(f\"‚úÖ TAX STATUS LABELS: {len(tax_status_counts)} categories\")\n",
    "            for status, count in tax_status_counts.head(5).items():\n",
    "                pct = (count / len(parcels_df)) * 100\n",
    "                print(f\"   {status}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüéØ RECOMMENDED LABELING STRATEGY:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"1. PRIMARY: Use FINAL_DETERMINATION from blight survey (highest quality)\")\n",
    "    print(\"2. SECONDARY: Use FIELD_DETERMINATION as backup/additional data\")\n",
    "    print(\"3. FEATURES: Combine with property conditions, tax status, assessed values\")\n",
    "    print(\"4. AUGMENT: Create synthetic labels using low assessed values\")\n",
    "    \n",
    "    return labels_summary\n",
    "\n",
    "# Create the labels\n",
    "if blight_df is not None and 'Parcels2025' in cod_datasets:\n",
    "    label_analysis = create_blight_labels(blight_df, cod_datasets['Parcels2025'])\n",
    "else:\n",
    "    print(\"‚ùå Cannot create labels - missing required datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Geodatabase Information üó∫Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üó∫Ô∏è GEODATABASE ANALYSIS\n",
      "============================================================\n",
      "üìç Geodatabase found at: ../../data/cod_layers_gdb/CODBaseUnitLayers.gdb\n",
      "üìÅ Number of files in geodatabase: 70\n",
      "\n",
      "üìã File types in geodatabase:\n",
      "  .atx: 24 files\n",
      "  .freelist: 1 files\n",
      "  .gdbindexes: 11 files\n",
      "  .gdbtable: 12 files\n",
      "  .gdbtablx: 12 files\n",
      "  .horizon: 4 files\n",
      "  .spx: 4 files\n",
      "  no_extension: 2 files\n",
      "\n",
      "üíæ Total geodatabase size: 284.45 MB\n",
      "\n",
      "‚ö†Ô∏è  Note: This is an ESRI geodatabase (.gdb) which requires\n",
      "   specialized GIS software (like ArcGIS or QGIS with GDAL) for full analysis.\n",
      "   Consider using geopandas or arcpy for detailed geodatabase exploration.\n"
     ]
    }
   ],
   "source": [
    "def analyze_geodatabase_info():\n",
    "    \"\"\"\n",
    "    Analyze the geodatabase structure (limited without specialized GIS tools)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üó∫Ô∏è GEODATABASE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Updated path for new location\n",
    "    gdb_path = \"../../data/cod_layers_gdb/CODBaseUnitLayers.gdb\"\n",
    "    \n",
    "    if os.path.exists(gdb_path):\n",
    "        print(f\"üìç Geodatabase found at: {gdb_path}\")\n",
    "        \n",
    "        # Get file information\n",
    "        files = os.listdir(gdb_path)\n",
    "        print(f\"üìÅ Number of files in geodatabase: {len(files)}\")\n",
    "        \n",
    "        # Categorize files by extension\n",
    "        extensions = {}\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1] if '.' in file else 'no_extension'\n",
    "            extensions[ext] = extensions.get(ext, 0) + 1\n",
    "        \n",
    "        print(\"\\nüìã File types in geodatabase:\")\n",
    "        for ext, count in sorted(extensions.items()):\n",
    "            print(f\"  {ext}: {count} files\")\n",
    "        \n",
    "        # Get total size\n",
    "        total_size = sum(os.path.getsize(os.path.join(gdb_path, f)) for f in files)\n",
    "        print(f\"\\nüíæ Total geodatabase size: {total_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        print(\"\\n‚ö†Ô∏è  Note: This is an ESRI geodatabase (.gdb) which requires\")\n",
    "        print(\"   specialized GIS software (like ArcGIS or QGIS with GDAL) for full analysis.\")\n",
    "        print(\"   Consider using geopandas or arcpy for detailed geodatabase exploration.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Geodatabase not found!\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Analyze geodatabase\n",
    "gdb_info = analyze_geodatabase_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary & Next Steps üìã\n",
    "\n",
    "Key findings for Project 2 blight classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä PROJECT 2 BLIGHT CLASSIFICATION - SUMMARY\n",
      "================================================================================\n",
      "‚úÖ Blight Survey Data: 62,824 rows, 30 columns\n",
      "   üéØ FINAL_DETERMINATION labels: 40,292\n",
      "   üéØ FIELD_DETERMINATION labels: 48,508\n",
      "‚úÖ COD Addresses: 490,561 rows, 12 columns\n",
      "‚úÖ COD Buildings: 409,301 rows, 8 columns\n",
      "‚úÖ COD Parcels2025: 378,366 rows, 52 columns\n",
      "‚úÖ Geodatabase: 284.45 MB spatial data\n",
      "\n",
      "üéØ BLIGHT CLASSIFICATION RECOMMENDATIONS:\n",
      "==================================================\n",
      "1. **PRIMARY LABELS**: Use FINAL_DETERMINATION from blight survey\n",
      "2. **BACKUP LABELS**: Use FIELD_DETERMINATION for additional training data\n",
      "3. **FEATURES**: Property conditions, tax status, assessed values, building age\n",
      "4. **AUGMENTATION**: Create binary labels from low property values (<$1000)\n",
      "5. **SPATIAL**: Use geodatabase for neighborhood context features\n",
      "\n",
      "üöÄ NEXT STEPS:\n",
      "- Clean and preprocess the blight survey labels\n",
      "- Join datasets on parcel_id for feature engineering\n",
      "- Create train/test splits preserving spatial distribution\n",
      "- Build baseline models (Random Forest, XGBoost)\n",
      "- Explore advanced models with spatial features\n",
      "\n",
      "üìä Dataset Ready for Machine Learning! ü§ñ\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä PROJECT 2 BLIGHT CLASSIFICATION - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if blight_df is not None:\n",
    "    print(f\"‚úÖ Blight Survey Data: {blight_df.shape[0]:,} rows, {blight_df.shape[1]} columns\")\n",
    "    \n",
    "    # Check key label columns\n",
    "    final_det_count = blight_df['FINAL_DETERMINATION'].notna().sum() if 'FINAL_DETERMINATION' in blight_df.columns else 0\n",
    "    field_det_count = blight_df['FIELD_DETERMINATION'].notna().sum() if 'FIELD_DETERMINATION' in blight_df.columns else 0\n",
    "    \n",
    "    print(f\"   üéØ FINAL_DETERMINATION labels: {final_det_count:,}\")\n",
    "    print(f\"   üéØ FIELD_DETERMINATION labels: {field_det_count:,}\")\n",
    "\n",
    "if cod_datasets:\n",
    "    for name, df in cod_datasets.items():\n",
    "        print(f\"‚úÖ COD {name}: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "\n",
    "print(\"‚úÖ Geodatabase: 284.45 MB spatial data\")\n",
    "\n",
    "print(\"\\nüéØ BLIGHT CLASSIFICATION RECOMMENDATIONS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. **PRIMARY LABELS**: Use FINAL_DETERMINATION from blight survey\")\n",
    "print(\"2. **BACKUP LABELS**: Use FIELD_DETERMINATION for additional training data\")\n",
    "print(\"3. **FEATURES**: Property conditions, tax status, assessed values, building age\")\n",
    "print(\"4. **AUGMENTATION**: Create binary labels from low property values (<$1000)\")\n",
    "print(\"5. **SPATIAL**: Use geodatabase for neighborhood context features\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"- Clean and preprocess the blight survey labels\")\n",
    "print(\"- Join datasets on parcel_id for feature engineering\")\n",
    "print(\"- Create train/test splits preserving spatial distribution\")\n",
    "print(\"- Build baseline models (Random Forest, XGBoost)\")\n",
    "print(\"- Explore advanced models with spatial features\")\n",
    "\n",
    "print(\"\\nüìä Dataset Ready for Machine Learning! ü§ñ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FINAL_DETERMINATION\n",
       "Property in Pipeline                   14547\n",
       "Other Resolution Pathways (Salvage)    11234\n",
       "Vacant (Not Blighted)                   4940\n",
       "No Action (Salvage)                     4460\n",
       " NAP (Salvage)                          4451\n",
       "ODM (Demo)                               634\n",
       "Noticeable Evidence of Blight             26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_df['FINAL_DETERMINATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midas_aug25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
